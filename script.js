// DOM Elements
const phoneNumberInput = document.getElementById('phoneNumber');
const dialpadButtons = document.querySelectorAll('.dialpad .buttons button');
const dialButton = document.getElementById('dialButton');
const hangupButton = document.getElementById('hangupButton');
const answerButton = document.getElementById('answerButton');
const muteButton = document.getElementById('muteButton');
const pauseButton = document.getElementById('pauseButton');
const restartButton = document.getElementById('restartButton');
const callStatusSpan = document.getElementById('callStatus');
const callDurationSpan = document.getElementById('callDuration');
const callLocationSpan = document.getElementById('callLocation');
const callIdSpan = document.getElementById('callId');
const aiAssistantStatusSpan = document.getElementById('aiAssistantStatus');
const serviceQualitySpan = document.getElementById('serviceQuality');
const scenarioButtons = document.querySelectorAll('.scenario-buttons button');
const waveformCanvas = document.getElementById('waveformCanvas');
const userSpeakingStatusSpan = document.getElementById('userSpeakingStatus');
const aiSpeakingStatusSpan = document.getElementById('aiSpeakingStatus');
const waitingStatusSpan = document.getElementById('waitingStatus');
const userVolumeControl = document.getElementById('userVolume');
const userVolumeValueSpan = document.getElementById('userVolumeValue');
const aiVolumeControl = document.getElementById('aiVolume');
const aiVolumeValueSpan = document.getElementById('aiVolumeValue');
const transcriptContentDiv = document.getElementById('transcriptContent');
const processingStatusContentDiv = document.getElementById('processingStatusContent');

// Canvas Context for Waveform
const ctx = waveformCanvas.getContext('2d');

// Call State Variables
let callState = 'idle'; // 'idle', 'dialing', 'connected', 'ended'
let callStartTime = null;
let callDurationInterval = null;
let currentCallId = null;
let aiAssistantStatus = 'ç¦»çº¿';

// Animation Variables
let animationFrameId = null; // To store requestAnimationFrame ID

// Simulation Variables
let simulationInterval = null;
let currentScenario = null;
let scenarioStep = 0;
let dialogueHistory = [];
let processingSteps = [];

// --- Utility Functions ---

/**
 * æ›´æ–°é€šè¯çŠ¶æ€æ˜¾ç¤º
 * @param {string} status - é€šè¯çŠ¶æ€ ('ç©ºé—²', 'æ‹¨å·ä¸­', 'å·²æ¥é€š', 'å·²ç»“æŸ')
 */
function updateCallStatus(status) {
    callStatusSpan.textContent = status;
    callState = status === 'ç©ºé—²' ? 'idle' : status === 'æ‹¨å·ä¸­' ? 'dialing' : status === 'å·²æ¥é€š' ? 'connected' : 'ended';
    updateButtonStates();
}

/**
 * æ›´æ–°AIåŠ©æ‰‹çŠ¶æ€æ˜¾ç¤º
 * @param {string} status - AIåŠ©æ‰‹çŠ¶æ€ ('åœ¨çº¿', 'ç¦»çº¿', 'å¤„ç†ä¸­')
 */
function updateAIAssistantStatus(status) {
    aiAssistantStatusSpan.textContent = status;
    aiAssistantStatus = status;
}

/**
 * æ›´æ–°é€šè¯æ—¶é•¿æ˜¾ç¤º
 */
function updateCallDuration() {
    if (callStartTime) {
        const elapsed = Math.floor((Date.now() - callStartTime) / 1000);
        const minutes = String(Math.floor(elapsed / 60)).padStart(2, '0');
        const seconds = String(elapsed % 60).padStart(2, '0');
        callDurationSpan.textContent = `${minutes}:${seconds}:00`; // Simplified to mm:ss:00 for demo
    }
}

/**
 * ç”Ÿæˆå”¯ä¸€çš„é€šè¯ID
 * @returns {string} é€šè¯ID
 */
function generateCallId() {
    const now = new Date();
    const year = now.getFullYear();
    const month = String(now.getMonth() + 1).padStart(2, '0');
    const day = String(now.getDate()).padStart(2, '0');
    const hour = String(now.getHours()).padStart(2, '0');
    const minute = String(now.getMinutes()).padStart(2, '0');
    const second = String(now.getSeconds()).padStart(2, '0');
    const random = String(Math.floor(Math.random() * 10000)).padStart(4, '0');
    return `CALL_${year}${month}${day}_${hour}${minute}${second}_${random}`;
}

/**
 * æ·»åŠ å¯¹è¯æ¶ˆæ¯åˆ°è½¬å½•åŒº
 * @param {'user' | 'ai' | 'system'} type - æ¶ˆæ¯ç±»å‹
 * @param {string} content - æ¶ˆæ¯å†…å®¹
 * @param {number} timestamp - æ—¶é—´æˆ³ (ç§’)
 * @param {number} confidence - è¯†åˆ«ç½®ä¿¡åº¦ (0-100%) (å¯é€‰)
 */
function addDialogueMessage(type, content, timestamp, confidence = null) {
    const messageElement = document.createElement('p');
    messageElement.classList.add(`${type}-message`);

    const minutes = String(Math.floor(timestamp / 60)).padStart(2, '0');
    const seconds = String(timestamp % 60).padStart(2, '0');
    const timeString = `[${minutes}:${seconds}]`;

    let prefix = '';
    if (type === 'user') {
        prefix = `ğŸ‘¤ å¸‚æ°‘ ${timeString}: `;
    } else if (type === 'ai') {
        prefix = `ğŸ¤– AIåŠ©æ‰‹ ${timeString}: `;
    } else if (type === 'system') {
        // System messages don't need a timestamp prefix in the example format
        messageElement.classList.add('system-message');
        messageElement.textContent = content;
        transcriptContentDiv.appendChild(messageElement);
        transcriptContentDiv.scrollTop = transcriptContentDiv.scrollHeight; // Auto scroll
        return;
    }

    messageElement.textContent = prefix + content;

    if (type === 'user' && confidence !== null) {
        const confidenceSpan = document.createElement('span');
        confidenceSpan.textContent = ` [ç½®ä¿¡åº¦: ${confidence.toFixed(0)}%]`;
        confidenceSpan.style.fontSize = '0.9em';
        const textSecondaryColor = getComputedStyle(document.documentElement).getPropertyValue('--text-secondary').trim();
        confidenceSpan.style.color = textSecondaryColor;
        messageElement.appendChild(confidenceSpan);
    }

    dialogueHistory.push({ type, content, timestamp, confidence });
    transcriptContentDiv.appendChild(messageElement);
    transcriptContentDiv.scrollTop = transcriptContentDiv.scrollHeight; // Auto scroll
}

/**
 * æ›´æ–°AIå¤„ç†çŠ¶æ€æ˜¾ç¤º
 * @param {string} step - å½“å‰å¤„ç†æ­¥éª¤æè¿°
 * @param {object} details - æ­¥éª¤è¯¦æƒ… (å¦‚æ„å›¾ã€è€—æ—¶ç­‰)
 */
function updateAIProcessingStatus(step, details = {}) {
    processingSteps.push({ step, details, timestamp: Math.floor((Date.now() - callStartTime) / 1000) });
    processingStatusContentDiv.innerHTML = ''; // Clear previous status

    processingSteps.forEach(item => {
        const statusElement = document.createElement('p');
        let content = `[${String(Math.floor(item.timestamp / 60)).padStart(2, '0')}:${String(item.timestamp % 60).padStart(2, '0')}] ${item.step}`;

        if (item.details.intent) {
            content += ` - ğŸ¯ æ„å›¾è¯†åˆ«: ${item.details.intent.name} (ç½®ä¿¡åº¦: ${item.details.intent.confidence.toFixed(0)}%)`;
        }
        if (item.details.knowledgeSearch) {
            content += ` - ğŸ“š çŸ¥è¯†åº“æ£€ç´¢: ${item.details.knowledgeSearch.query} (ç»“æœ: ${item.details.knowledgeSearch.results})`;
        }
        if (item.details.routing) {
            content += ` - ğŸ¯ åˆ†æµå»ºè®®: ${item.details.routing.departments.join(', ')}`;
        }
        if (item.details.timing) {
             content += ` - âš¡ è€—æ—¶: ${item.details.timing.total}ms`;
        }
        // Add other details as needed based on the structure

        statusElement.textContent = content;
        processingStatusContentDiv.appendChild(statusElement);
    });
     // Optionally, add current total time
     if (callStartTime) {
        const totalElapsed = Date.now() - callStartTime;
        const totalTimeElement = document.createElement('p');
        totalTimeElement.textContent = `âš¡ æ€»å¤„ç†è€—æ—¶: ${totalElapsed.toFixed(0)}ms`;
        processingStatusContentDiv.appendChild(totalTimeElement);
     }
}

/**
 * æ¨¡æ‹Ÿè¯­éŸ³æ³¢å½¢åŠ¨ç”»
 * @param {'user' | 'ai' | 'idle'} status - è¯´è¯çŠ¶æ€
 */
function animateWaveform(status) {
    // Cancel previous animation frame if any
    if (animationFrameId) {
        cancelAnimationFrame(animationFrameId);
    }

    const width = waveformCanvas.width;
    const height = waveformCanvas.height;
    ctx.clearRect(0, 0, width, height);

    if (callState === 'ended' || callState === 'idle') {
         ctx.strokeStyle = 'gray';
         ctx.lineWidth = 1;
         ctx.beginPath();
         ctx.moveTo(0, height / 2);
         ctx.lineTo(width, height / 2);
         ctx.stroke();
         userSpeakingStatusSpan.style.fontWeight = 'normal';
         aiSpeakingStatusSpan.style.fontWeight = 'normal';
         waitingStatusSpan.style.fontWeight = 'bold';
         animationFrameId = null; // Clear animation ID when idle/ended
         return;
    }

    const color = status === 'user' ? 'red' : 'blue';
    ctx.strokeStyle = color;
    ctx.lineWidth = 2;

    ctx.beginPath();
    ctx.moveTo(0, height / 2);

    for (let i = 0; i < width; i++) {
        const amplitude = Math.random() * (height / 4);
        const y = height / 2 + Math.sin(i * 0.05) * amplitude;
        ctx.lineTo(i, y);
    }
    ctx.stroke();

    userSpeakingStatusSpan.style.fontWeight = status === 'user' ? 'bold' : 'normal';
    aiSpeakingStatusSpan.style.fontWeight = status === 'ai' ? 'bold' : 'normal';
    waitingStatusSpan.style.fontWeight = 'normal';

    // Store the new animation frame ID
    animationFrameId = requestAnimationFrame(() => animateWaveform(status));
}

/**
 * æ›´æ–°æŒ‰é’®çš„å¯ç”¨çŠ¶æ€
 */
function updateButtonStates() {
    dialButton.style.display = callState === 'idle' ? 'block' : 'none';
    hangupButton.style.display = callState !== 'idle' ? 'block' : 'none';
    answerButton.style.display = 'none'; // Assuming incoming calls are not part of this demo

    const callActive = callState === 'connected' || callState === 'dialing';
    muteButton.disabled = !callActive;
    pauseButton.disabled = !callActive;
    scenarioButtons.forEach(button => button.disabled = !callActive);

    // Initial speaking status
    if (callState === 'connected') {
        animateWaveform('idle'); // Start idle animation when connected
    } else {
        animateWaveform('idle'); // Default to idle when not connected or ended
    }

    updateAIAssistantStatus(callState === 'connected' ? 'åœ¨çº¿' : 'ç¦»çº¿');
}

/**
 * æ¸…ç©ºæ‰€æœ‰çŠ¶æ€ï¼Œå›åˆ°åˆå§‹çŠ¶æ€
 */
function resetDemo() {
    clearInterval(callDurationInterval);
    // Stop the waveform animation
    if (animationFrameId) {
        cancelAnimationFrame(animationFrameId);
    }
    animationFrameId = null;

    // Clear any pending simulation timeouts
    // This is a simplification. A more robust solution would track all timeout IDs.
    // For this demo, setting callState to idle prevents further execution in callbacks.
    
    callState = 'idle';
    callStartTime = null;
    currentCallId = null;
    dialogueHistory = [];
    processingSteps = [];

    phoneNumberInput.value = '12345';
    callStatusSpan.textContent = 'ç©ºé—²';
    callDurationSpan.textContent = '00:00:00';
    callLocationSpan.textContent = 'æ¨¡æ‹Ÿåœ°åŒº';
    callIdSpan.textContent = 'N/A';
    aiAssistantStatusSpan.textContent = 'ç¦»çº¿';
    serviceQualitySpan.textContent = 'N/A';
    transcriptContentDiv.innerHTML = '';
    processingStatusContentDiv.innerHTML = '';

    updateButtonStates();
    animateWaveform('idle'); // Ensure waveform is reset to idle state
}

// --- Simulation Logic ---

/**
 * æ¨¡æ‹Ÿå®Œæ•´çš„æ‹¨å·å’Œæ¥é€šè¿‡ç¨‹
 */
function simulateCallStart() {
    updateCallStatus('æ‹¨å·ä¸­');
    callIdSpan.textContent = generateCallId();
    callLocationSpan.textContent = 'åŒ—äº¬å¸‚æœé˜³åŒº'; // Simulated location
    serviceQualitySpan.textContent = 'â­â­â­â­â­'; // Simulated quality

    // Simulate dialing sound (optional, requires audio API)
    // setTimeout(() => { /* play dialing tone */ }, 500);

    setTimeout(() => {
        // Only proceed if still in dialing state (not reset)
        if (callState !== 'dialing') return;

        updateCallStatus('å·²æ¥é€š');
        callStartTime = Date.now();
        callDurationInterval = setInterval(updateCallDuration, 1000);
        animateWaveform('idle');
        addDialogueMessage('system', 'é€šè¯å·²æ¥é€š', 0);
        simulateAIPrompt();
    }, 3000); // Simulate 3 seconds to connect
}

/**
 * æ¨¡æ‹ŸAIåŠ©æ‰‹å¼€åœºç™½
 */
function simulateAIPrompt() {
     // Only proceed if call is connected
     if (callState !== 'connected') return;

     updateAIAssistantStatus('å¤„ç†ä¸­');
     animateWaveform('ai');
     // Simulate AI thinking/processing
     updateAIProcessingStatus('ğŸ¤– AIåŠ©æ‰‹: æ­£åœ¨å‡†å¤‡å¼€åœºç™½...');
     setTimeout(() => {
         // Only proceed if call is connected
         if (callState !== 'connected') return;

         updateAIProcessingStatus('ğŸ¤– AIåŠ©æ‰‹: å¼€åœºç™½ç”Ÿæˆå®Œæˆ', { timing: { total: 800 } });
         addDialogueMessage('ai', 'æ‚¨å¥½ï¼Œè¿™é‡Œæ˜¯12345æ”¿åŠ¡æœåŠ¡çƒ­çº¿ï¼Œæˆ‘æ˜¯AIæ™ºèƒ½åŠ©æ‰‹å°æ”¿ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ', Math.floor((Date.now() - callStartTime) / 1000));
         animateWaveform('idle');
         updateAIAssistantStatus('åœ¨çº¿');
     }, 1500); // Simulate AI response time
}

/**
 * æ¨¡æ‹Ÿç”¨æˆ·è¾“å…¥å’ŒAIå›å¤æµç¨‹
 * @param {string} userInput - æ¨¡æ‹Ÿçš„ç”¨æˆ·è¾“å…¥æ–‡æœ¬
 */
function simulateUserInteraction(userInput) {
    if (callState !== 'connected') return;

    const userTimestamp = Math.floor((Date.now() - callStartTime) / 1000);
    addDialogueMessage('user', userInput, userTimestamp, 95); // Simulate high confidence

    // Simulate AI processing flow based on scenario/input
    simulateAIResponse(userInput);
}

/**
 * æ¨¡æ‹ŸAIå¤„ç†å’Œå›å¤
 * @param {string} userInput - ç”¨æˆ·è¾“å…¥æ–‡æœ¬
 */
function simulateAIResponse(userInput) {
    // Only proceed if call is connected
    if (callState !== 'connected') return;

    updateAIAssistantStatus('å¤„ç†ä¸­');
    animateWaveform('user'); // Simulate listening to user

    // Simulate processing steps over time
    const processingTimes = {
        recognizing: 500,
        understanding: 700,
        searching: 1000,
        routing: 400,
        generating: 800
    };
    let totalProcessingTime = 0;

    // Determine simulated intent and routing based on input
    let simulatedIntent = { name: 'æœªçŸ¥æ„å›¾', confidence: 80 };
    let simulatedRouting = { departments: ['å¾…å®š'], priority: 5 };

    if (userInput.includes('å™ªéŸ³') || userInput.includes('å¤ªåµ')) {
        simulatedIntent = { name: 'å™ªéŸ³æŠ•è¯‰', confidence: 96 };
        simulatedRouting = { departments: ['ç¯ä¿å±€', 'åŸç®¡å±€'], priority: 1 };
    } else if (userInput.includes('è¥ä¸šæ‰§ç…§') || userInput.includes('æ€ä¹ˆåŠè¯')) {
        simulatedIntent = { name: 'è¯ä»¶åŠç†å’¨è¯¢', confidence: 94 };
        simulatedRouting = { departments: ['æ”¿åŠ¡æœåŠ¡ä¸­å¿ƒ'], priority: 2 };
    } else if (userInput.includes('å—ä¼¤') || userInput.includes('ç´§æ€¥')) {
        simulatedIntent = { name: 'ç´§æ€¥æƒ…å†µå¤„ç†', confidence: 98 };
        simulatedRouting = { departments: ['å…¬å®‰å±€', 'å«å¥å§”'], priority: 0 }; // Highest priority
    } else if (userInput.includes('ä¹±åœ') || userInput.includes('åœè½¦') || userInput.includes('æ¶ˆé˜²é€šé“')) {
         simulatedIntent = { name: 'è¿ç« åœè½¦ä¸¾æŠ¥', confidence: 95 };
         simulatedRouting = { departments: ['äº¤è­¦éƒ¨é—¨', 'åŸç®¡å±€'], priority: 1 };
    }
    // Add more intent/routing mappings as needed

    setTimeout(() => {
        // Only proceed if call is connected
        if (callState !== 'connected') return;
        updateAIProcessingStatus('ğŸ¯ æ„å›¾è¯†åˆ«', { intent: simulatedIntent, timing: { total: processingTimes.recognizing } });
        totalProcessingTime += processingTimes.recognizing;
        setTimeout(() => {
             // Only proceed if call is connected
             if (callState !== 'connected') return;
             updateAIProcessingStatus('ğŸ“š çŸ¥è¯†åº“æ£€ç´¢', { knowledgeSearch: { query: userInput, results: 3, sources: ['æ”¿ç­–åº“', 'é—®ç­”é›†'] }, timing: { total: processingTimes.understanding } });
             totalProcessingTime += processingTimes.understanding;
             setTimeout(() => {
                  // Only proceed if call is connected
                  if (callState !== 'connected') return;
                  updateAIProcessingStatus('ğŸ” ä¿¡æ¯åŒ¹é…', { timing: { total: processingTimes.searching } });
                  totalProcessingTime += processingTimes.searching;
                  setTimeout(() => {
                       // Only proceed if call is connected
                       if (callState !== 'connected') return;
                       updateAIProcessingStatus('ğŸ¯ åˆ†æµå»ºè®®', { routing: simulatedRouting, timing: { total: processingTimes.routing } });
                       totalProcessingTime += processingTimes.routing;
                       setTimeout(() => {
                            // Only proceed if call is connected
                            if (callState !== 'connected') return;
                            updateAIProcessingStatus('ğŸ“ å›å¤ç”Ÿæˆ', { timing: { total: processingTimes.generating } });
                            totalProcessingTime += processingTimes.generating;
                            setTimeout(() => {
                                 // Only proceed if call is connected
                                 if (callState !== 'connected') return;
                                updateAIProcessingStatus('âœ… å¤„ç†å®Œæˆ', { timing: { total: totalProcessingTime } });
                                simulateAIOutput(userInput);
                            }, processingTimes.generating);
                       }, processingTimes.routing);
                  }, processingTimes.searching);
             }, processingTimes.understanding);
        }, processingTimes.recognizing);
    }, 500); // Initial delay before processing starts
}

/**
 * æ¨¡æ‹ŸAIçš„è¯­éŸ³è¾“å‡ºå’Œè½¬å½•
 * @param {string} userInput - ç”¨æˆ·è¾“å…¥æ–‡æœ¬ (ç”¨äºå†³å®šAIå›å¤)
 */
function simulateAIOutput(userInput) {
    // Only proceed if call is connected
    if (callState !== 'connected') return;

     animateWaveform('ai');
     const aiTimestamp = Math.floor((Date.now() - callStartTime) / 1000);
     let aiResponse = 'æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£æ‚¨çš„é—®é¢˜ã€‚'; // Default response

     // Simple logic to pick a response based on input (for demo)
     if (userInput.includes('å™ªéŸ³') || userInput.includes('å¤ªåµ')) {
         aiResponse = 'æ ¹æ®æ‚¨åæ˜ çš„å™ªéŸ³é—®é¢˜ï¼Œæˆ‘ä¸ºæ‚¨åˆ†æäº†å¤„ç†æ–¹æ¡ˆï¼šæ‚¨å¯ä»¥å°è¯•ä¸æ¥¼ä¸Šé‚»å±…æ²Ÿé€šï¼Œæˆ–è”ç³»ç‰©ä¸šã€‚å¦‚é—®é¢˜æŒç»­ï¼Œå¯ä»¥æ‹¨æ‰“ç¯ä¿çƒ­çº¿12369ã€‚';
     } else if (userInput.includes('è¥ä¸šæ‰§ç…§') || userInput.includes('æ€ä¹ˆåŠè¯')) {
         aiResponse = 'åŠç†è¥ä¸šæ‰§ç…§éœ€è¦èº«ä»½è¯æ˜ã€åœºåœ°è¯æ˜ç­‰ææ–™ã€‚å…·ä½“æµç¨‹å’Œæ‰€éœ€ææ–™è¯·å‚è€ƒæ”¿åŠ¡æœåŠ¡ä¸­å¿ƒæŒ‡å—ã€‚æ‚¨å¯ä»¥åœ¨çº¿æŸ¥è¯¢æˆ–å‰å¾€çª—å£åŠç†ã€‚';
     } else if (userInput.includes('å—ä¼¤') || userInput.includes('ç´§æ€¥')) {
          aiResponse = 'æ£€æµ‹åˆ°æ‚¨å¯èƒ½é‡åˆ°ç´§æ€¥æƒ…å†µï¼å¦‚æœæ˜¯ç”Ÿå‘½å®‰å…¨ç´§æ€¥æƒ…å†µï¼Œè¯·ç«‹å³æŒ‚æ–­å¹¶æ‹¨æ‰“110ã€120ã€119ã€‚å¦‚éœ€ç»§ç»­å’¨è¯¢ï¼Œè¯·è¯´"ç»§ç»­å’¨è¯¢"ã€‚';
     } else if (userInput.includes('ä¹±åœ') || userInput.includes('åœè½¦') || userInput.includes('æ¶ˆé˜²é€šé“')) {
         aiResponse = 'é’ˆå¯¹å°åŒºè½¦è¾†ä¹±åœé—®é¢˜ï¼Œç‰¹åˆ«æ˜¯å ç”¨æ¶ˆé˜²é€šé“çš„æƒ…å†µï¼Œæ‚¨å¯ä»¥è”ç³»ç‰©ä¸šç®¡ç†å¤„åè°ƒï¼Œæˆ–è€…æ‹¨æ‰“äº¤é€šç®¡ç†éƒ¨é—¨æˆ–åŸç®¡éƒ¨é—¨çš„ä¸¾æŠ¥ç”µè¯ã€‚é€šå¸¸å¯ä»¥æ‹¨æ‰“122äº¤é€šäº‹æ•…æŠ¥è­¦ç”µè¯æˆ–å‘å½“åœ°åŸç®¡éƒ¨é—¨åæ˜ ã€‚';
     }
     // Add more conditions for other scenarios

     addDialogueMessage('ai', aiResponse, aiTimestamp);
     animateWaveform('idle'); // AI finished speaking
     updateAIAssistantStatus('åœ¨çº¿');
}

// --- Event Listeners ---

// Dialpad button clicks
dialpadButtons.forEach(button => {
    button.addEventListener('click', () => {
        // Allow dialpad input only in idle state
        if (callState === 'idle') {
            phoneNumberInput.value += button.getAttribute('data-value');
        }
         // Play dialpad tone (optional, requires audio API)
         // const tone = new Audio(`tones/${button.getAttribute('data-value')}.mp3`);
         // tone.play();
    });
});

// Dial button click
dialButton.addEventListener('click', () => {
    // Only allow dialing in idle state
    if (callState === 'idle') {
        simulateCallStart();
    }
});

// Hangup button click
hangupButton.addEventListener('click', () => {
    // Allow hanging up if not already ended
    if (callState !== 'ended' && callState !== 'idle') {
        clearInterval(callDurationInterval);
         // Stop the waveform animation
        if (animationFrameId) {
            cancelAnimationFrame(animationFrameId);
        }
        animationFrameId = null;

        updateCallStatus('å·²ç»“æŸ');
        addDialogueMessage('system', 'é€šè¯å·²ç»“æŸ', Math.floor((Date.now() - callStartTime) / 1000));
        animateWaveform('idle');
        updateAIAssistantStatus('ç¦»çº¿');
        // Optionally, reset after a short delay
        // setTimeout(resetDemo, 5000);
    }
});

// Restart button click
restartButton.addEventListener('click', resetDemo);

// Scenario button clicks
scenarioButtons.forEach(button => {
    button.addEventListener('click', () => {
        // Only allow scenario selection when connected
        if (callState === 'connected') {
            const scenario = button.getAttribute('data-scenario');
            // For a simple demo, we'll just trigger a simulated user interaction based on the scenario
            let simulatedInput = '';
            if (scenario === 'noiseComplaint') {
                simulatedInput = 'æ¥¼ä¸Šé‚»å±…å¤ªåµäº†ï¼Œæˆ‘è¦æŠ•è¯‰å™ªéŸ³ã€‚';
            } else if (scenario === 'parkingViolation') {
                 simulatedInput = 'å°åŒºé‡Œæœ‰è½¦ä¹±åœï¼Œå µä½æ¶ˆé˜²é€šé“äº†ã€‚';
            } else if (scenario === 'emergency') {
                 simulatedInput = 'æœ‰äººå—ä¼¤äº†ï¼Œæƒ…å†µç´§æ€¥ï¼';
            } else if (scenario === 'documentProcess') {
                 simulatedInput = 'è¯·é—®æ€ä¹ˆåŠè¥ä¸šæ‰§ç…§ï¼Ÿéœ€è¦ä»€ä¹ˆææ–™ï¼Ÿ';
            }
            simulateUserInteraction(simulatedInput);
        }
    });
});

// Volume control event listeners
userVolumeControl.addEventListener('input', (event) => {
    userVolumeValueSpan.textContent = `${event.target.value}%`;
    // In a real app, adjust user input volume
});

aiVolumeControl.addEventListener('input', (event) => {
    aiVolumeValueSpan.textContent = `${event.target.value}%`;
    // In a real app, adjust AI output volume (e.g., for TTS playback)
});

muteButton.addEventListener('click', () => {
    // Toggle mute state
    const isMuted = muteButton.textContent.includes('å–æ¶ˆ');
    if (isMuted) {
        muteButton.textContent = 'ğŸ”‡ é™éŸ³';
        // Unmute audio input/output
    } else {
        muteButton.textContent = 'ğŸ”Š å–æ¶ˆé™éŸ³';
        // Mute audio input/output
    }
});

pauseButton.addEventListener('click', () => {
     // Toggle pause state
    const isPaused = pauseButton.textContent.includes('ç»§ç»­');
    if (isPaused) {
        pauseButton.textContent = 'â¸ï¸ æš‚åœ';
        // Resume simulation/audio
        if (callDurationInterval === null && callState === 'connected') {
             callDurationInterval = setInterval(updateCallDuration, 1000);
        }
         animateWaveform(aiAssistantStatus === 'å¤„ç†ä¸­' ? 'ai' : 'idle');
    } else {
        pauseButton.textContent = 'â–¶ï¸ ç»§ç»­';
        // Pause simulation/audio
        clearInterval(callDurationInterval);
        animateWaveform('idle'); // Pause waveform animation
    }
});

// --- Initial Setup ---

// Draw initial waveform state (idle)
animateWaveform('idle');
updateButtonStates();

// Note: In a real application, you would initialize audio contexts,
// connect to ASR/TTS/NLU services, and handle real-time audio streams.
// This script provides a simplified simulation of the UI updates based on the PRD. 